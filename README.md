# ğŸ§  Mindbook Backend API

A powerful FastAPI-based backend for **Mindbook** â€” an intelligent document management and RAG (Retrieval-Augmented Generation) system that enables smart interactions with your documents.

---

## âœ¨ Features

- **ğŸ” Authentication** â€” Clerk-based user authentication and authorization
- **ğŸ“ Project Management** â€” Create, manage, and organize document projects
- **ğŸ“„ Document Processing** â€” Ingest and process multiple document types (PDFs, web pages, etc.)
- **ğŸ¤– AI-Powered Chat** â€” Chat with your documents using advanced RAG techniques
- **ğŸ” Intelligent Retrieval** â€” Context-aware document search and retrieval
- **âš¡ Async Processing** â€” Background task processing with Celery and Redis
- **â˜ï¸ Cloud Storage** â€” AWS S3 and Cloudflare R2 integration for file storage

---

## ğŸ—ï¸ Architecture

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                 # AI Agent implementations
â”‚   â”‚   â”œâ”€â”€ simple_agent/       # Basic agent for straightforward queries
â”‚   â”‚   â””â”€â”€ supervisor_agent/   # Advanced multi-agent supervisor
â”‚   â”œâ”€â”€ config/                 # Application configuration
â”‚   â”œâ”€â”€ middleware/             # Custom middleware (logging, auth)
â”‚   â”œâ”€â”€ models/                 # Data models and schemas
â”‚   â”œâ”€â”€ rag/                    # RAG system components
â”‚   â”‚   â”œâ”€â”€ ingestion/          # Document ingestion pipeline
â”‚   â”‚   â””â”€â”€ retrieval/          # Document retrieval logic
â”‚   â”œâ”€â”€ routes/                 # API route handlers
â”‚   â”‚   â”œâ”€â”€ chatRoutes.py       # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ projectRoutes.py    # Project management endpoints
â”‚   â”‚   â”œâ”€â”€ projectFilesRoutes.py # File management endpoints
â”‚   â”‚   â””â”€â”€ userRoutes.py       # User endpoints
â”‚   â”œâ”€â”€ services/               # External service integrations
â”‚   â”‚   â”œâ”€â”€ celery.py           # Celery task queue
â”‚   â”‚   â”œâ”€â”€ clerkAuth.py        # Clerk authentication
â”‚   â”‚   â”œâ”€â”€ cloudflareR2.py     # Cloudflare R2 storage
â”‚   â”‚   â”œâ”€â”€ llm.py              # LLM configuration
â”‚   â”‚   â”œâ”€â”€ supabase.py         # Supabase client
â”‚   â”‚   â””â”€â”€ webScrapper.py      # Web scraping utilities
â”‚   â”œâ”€â”€ utils/                  # Utility functions
â”‚   â””â”€â”€ server.py               # FastAPI application entry point
â”œâ”€â”€ supabase/                   # Supabase configuration & migrations
â”œâ”€â”€ docker-compose.yml          # Docker services configuration
â”œâ”€â”€ Dockerfile                  # API container definition
â”œâ”€â”€ Makefile                    # Development shortcuts
â””â”€â”€ pyproject.toml              # Python dependencies (Poetry)
```

### System Design Diagrams

> ğŸ“ Architecture diagrams are located in `../frontend/public/`

#### High-Level Design
![High Level Design](../frontend/public/hld.png)

#### RAG Pipeline Architecture
![RAG Pipeline](../frontend/public/Rag_pipeline_architecture.png)

#### RAG Agent Flow
![RAG Agent](../frontend/public/rag_agent.png)

#### Retrieval Pipeline
![Retrieval Pipeline](../frontend/public/retreival_pipeline.png)

#### Database Schema
![Database Schema](../frontend/public/database_schema.png)

#### Server Dependency Architecture
![Server Architecture](../frontend/public/server_dependency_architecture.png)

---

## ğŸš€ Quick Start

### Prerequisites

- **Python** 3.10 â€“ 3.13
- **Docker** & **Docker Compose**
- **Poetry** (for dependency management)
- **Supabase CLI** (for local database)

### 1. Clone & Navigate

```bash
cd backend
```

### 2. Environment Setup

Copy the sample environment file and configure your credentials:

```bash
cp .env.sample .env
```

Fill in the required environment variables:

| Variable | Description |
|----------|-------------|
| `SUPABASE_API_URL` | Local Supabase API URL (e.g., `http://localhost:54321`) |
| `SUPABASE_SECRET_KEY` | Supabase service role key |
| `CLERK_SECRET_KEY` | Clerk authentication secret |
| `AWS_ACCESS_KEY_ID` | AWS credentials for S3 |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key |
| `S3_BUCKET_NAME` | S3 bucket for file storage |
| `REDIS_URL` | Redis connection URL |
| `OPENAI_API_KEY` | OpenAI API key for LLM |
| `TAVILY_API_KEY` | Tavily API for web search |
| `LANGSMITH_API_KEY` | LangSmith for tracing (optional) |

### 3. Start Services

Using the **Makefile** (recommended):

```bash
# Start all services (Supabase, Redis, API, Celery Worker)
make start

# View logs
make logs-api     # API server logs
make logs-worker  # Celery worker logs
make logs-redis   # Redis logs

# Stop all services
make stop

# Clean everything (removes containers, images, volumes)
make clean
```

Or using **Docker Compose** directly:

```bash
docker-compose up -d
```

### 4. Access the API

- **API Server**: [http://localhost:8000](http://localhost:8000)
- **Swagger Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **ReDoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)
- **Health Check**: [http://localhost:8000/health](http://localhost:8000/health)

---

## ğŸ“š API Endpoints

### Health
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Check API health status |

### User Management
| Method | Endpoint | Description |
|--------|----------|-------------|
| `*` | `/api/user/*` | User-related operations |

### Projects
| Method | Endpoint | Description |
|--------|----------|-------------|
| `*` | `/api/projects/*` | Project CRUD operations |

### Project Files
| Method | Endpoint | Description |
|--------|----------|-------------|
| `*` | `/api/projects/*` | File upload, processing, management |

### Chat
| Method | Endpoint | Description |
|--------|----------|-------------|
| `*` | `/api/chats/*` | AI-powered document chat |

> ğŸ“– For detailed API documentation, visit the Swagger UI at `/docs` after starting the server.

---

## ğŸ› ï¸ Development

### Local Development (without Docker)

```bash
# Install dependencies
poetry install

# Start Supabase locally
npx supabase start

# Start Redis (if not using Docker)
redis-server

# Run the development server
uvicorn src.server:app --reload --host 0.0.0.0 --port 8000

# In another terminal, start Celery worker
celery -A src.services.celery:app worker --loglevel=info --pool=threads
```

### Running Tests

```bash
poetry run pytest
```

---

## ğŸ³ Docker Services

The `docker-compose.yml` defines three services:

| Service | Container | Port | Description |
|---------|-----------|------|-------------|
| `redis` | redis | 6379 | Message broker for Celery |
| `api` | server | 8000 | FastAPI application |
| `worker` | celery-worker | â€” | Background task processor |

---

## ğŸ“¦ Key Dependencies

| Package | Purpose |
|---------|---------|
| **FastAPI** | Web framework for building APIs |
| **Uvicorn** | ASGI server |
| **LangChain** | LLM orchestration and RAG |
| **LangChain OpenAI** | OpenAI integration |
| **Celery** | Distributed task queue |
| **Redis** | Message broker & caching |
| **Supabase** | Database and authentication |
| **Unstructured** | Document parsing and processing |
| **Boto3** | AWS S3 integration |
| **Clerk** | User authentication |
| **Structlog** | Structured logging |
| **RAGAS** | RAG evaluation framework |

---

## ğŸ”§ Configuration

### Logging

The application uses **structlog** for structured logging. Logs are stored in the `logs/` directory and output to stdout for container environments.

### Database

Supabase is used as the primary database. Migrations are stored in `supabase/migrations/`.

To apply migrations:

```bash
npx supabase db push
```

---

## ğŸ“ License

This project is private and proprietary.

---

## ğŸ‘¤ Author

**harrykamboj1** â€” [singhharnoor116@gmail.com](mailto:singhharnoor116@gmail.com)
